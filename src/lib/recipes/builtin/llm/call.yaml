# LLM Call Recipe
# Basic LLM invocation with configurable prompts

id: llm.call
name: LLM Call
description: Call the configured LLM with a prompt
category: AI
icon: Sparkles

inputSchema:
  - key: prompt
    label: Prompt
    type: string
    widget: textarea
    required: true
    placeholder: "Enter your prompt..."
    connection:
      input: true
      output: true

  - key: systemPrompt
    label: System Prompt
    type: string
    widget: textarea
    placeholder: "Optional system instructions..."
    connection:
      input: true
      output: true

  - key: temperature
    label: Temperature
    type: number
    widget: slider
    default: 0.7
    min: 0
    max: 2
    step: 0.1

  - key: maxTokens
    label: Max Tokens
    type: number
    widget: number
    default: 2048
    min: 1
    max: 8192

  - key: response
    label: Response
    type: string
    widget: none
    disabled: true
    connection:
      output: true

outputSchema:
  type: text
  description: LLM response text

executor:
  type: llm-agent
  userPromptTemplate: "{{prompt}}"
  systemPrompt: "{{systemPrompt}}"
  parseAs: text
